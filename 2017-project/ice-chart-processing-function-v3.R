################################################################
#  Script written by Paul Regular (Paul.Regular@dfo-mpo.gc.ca)  #
#  Created 201X-XX-XX, R version 3.X.x (201X-XX-XX)             #
#  Last modified by Paul Regular, Alejandro Buren, and Keith Lewis 2017-07.04 #
#  See Ale's optimization functions at the end
################################################################

# The purpose of this file is to store the funcitons required for:
#1) eggAttr(): function for extracting egg attributes from EGG_ATTR string
#2) attrTab(): extracting attribute table from raw e00 file (not 100% successful)
#3) e00Download(): download e00 data from environment Canada - see function for notes
#4) eggAttr.cols(): Turn the eggAttr data into columns that can be querried
#5) eggAttr.query(): query the egg/ice data for concentration and stage among polygons 
#6) iceSubset(): sub.egg object (SPDF) generated by the calcAreaVolume function and modified by eggAttr.cols(),and egg.Attr.query()
#7) iceTiming (): calculate the minimum latitude of ice in a given year - this represents timing of the retreat
#8) withinPolyAreaA(): query the egg/ice data for concentration and stage among polygons (could not generalize this so 4 functions instead of one)
#9) iceArea(): using the attribute table to calculate total ice area
#10) iceVolume(): using attribute table to calculate total ice volume
#11) plotIce: function for plotting ice charts 
#12) e00_to_SpatialPolygonDataframe(): e00 to avc_data (coverages) and then to SpatialPolygonsDAtaframe in sp_data
#13) loadMap(): loads maps from Rdata file
#14) subsetProject(): subset and project to WGS84 (poorly named)
#15) filterEgg(): Apply filters and return to lcc projection
#16) calcLatLong(): subset the sub.egg data by ice concentration and stage of development and calculate the minimum latitude (timing of iceretreat) using sub functions - needed to proceed with area and volume calculations
#17) calcPolyA(): calculates the area of each polygon in SpatailPolygonDataframe
#18) trendsCalc(): use iceArea() and iceVolume() to calculate the area and volume of ice for specified area
#19) calcAreaVolLat(): Main function that brings together all the other functions
#20) multiplot
#21) several lookat functions
#22) Ale's optimization functions


#) LookAt function - functions for looking at various stages of the egg data and checking that modifications are correct.


# V1 - first attempt at taking Paul's code and making functions
# v2 - add functions to subset ice
# v3 - a substantial reworking of the file - the calcAreaVol() was reworked into calcAreaVolLat() and was broken up into multiple subfunctions
## Custom functions 

##' eggAttr()-----------------------------
##' function for extracting egg attributes from EGG_ATTR string - used in iceArea() to elegantly extract values from the EGG_ATTR string and calculate area
#' Egg data Attributes
#'
#' @param x where x is an object
#'
#' @return
#' @export
#'
#' @examples
#' 
eggAttr <- function(x) {
  if(any(grepl("_", x))) {
    sx <- strsplit(x, "_")
  } else {
    sx <- vector("list", length(x))
  }
  sx <- lapply(sx, function(i) {
    newi <- i
    if (length(i) == 0) {
      newi <- rep(NA, 17)
    } else {
      newi[newi == "@" | newi == "X"] <- NA
    }
    newi
  }
  )
  sx <- data.frame(do.call(rbind, sx))
  names(sx) <- c("E_CT","E_CA","E_CB","E_CC","E_CD","E_SO","E_SA","E_SB","E_SC","E_SD","E_SE","E_FA","E_FB","E_FC","E_FD","E_FE","E_CS")
  sx
}

##' attrTab()-----------------------------
##' function for extracting attribute table from raw e00 file (not 100% successful)
#' Attribute Table
#'
#' @param x = data 
#'
#' @return
#' @export
#'
#' @examples
attrTab <- function(x) {
  
  full.pattern <- c("Land", "No data", "Ice free", "Open water", 
                    "Fast ice", "Remote egg", "Bergy water", "Egg")
  partial.pattern <- c("Land", "No", "Ice", "Open", 
                       "Fast", "Remote", "Bergy", "Egg")
  p <- paste(partial.pattern, collapse = "|")
  i <- grep(p, x) # find matches to A_LEGEND types
  subx <- x[head(i, 1):tail(i, 1)]
  subi <- grep(p, subx) # revise i
  id <- aleg <- egg.attr <- rep(NA, length(subi))
  for(i in seq_along(subi)) {
    j <- regexpr(p, subx[subi[i]])
    aleg[i] <- regmatches(subx[subi[i]], j)
    id[i] <- as.integer(substr(subx[subi[i]], j-3, j-1)) # polygon id usually 3 characters before A_LEGEND text
    e <- paste(subx[subi[i]+1:2], collapse = "") # looks like EGG_ATTR text is 1-2 records ahead of A_LEGEND text
    if(grepl("_@_", e)) {
      j <- gregexpr("_", e)
      e <- substr(e, max(j[[1]])-35, max(j[[1]])+3)
      egg.attr[i] <- gsub("^\\s+|\\s+$", "", e) # clear spaces
    } else {
      egg.attr[i] <- NA
    }
  }
  attr.tab <- data.frame(ID = id, A_LEGEND = aleg, EGG_ATTR = egg.attr)
  attr.tab <- attr.tab[!is.na(attr.tab$ID), ] # chuck records missing id
  attr.tab <- attr.tab[!duplicated(attr.tab$ID), ] # remove duplicate IDs
  attr.tab <- cbind(attr.tab, eggAttr(attr.tab$EGG_ATTR)) # split egg attributes and add 
  attr.tab$A_LEGEND[is.na(attr.tab$A_LEGEND)] <- "No data"
  attr.tab$A_LEGEND <- full.pattern[match(attr.tab$A_LEGEND, partial.pattern)]
  row.names(attr.tab) <- attr.tab$ID
  attr.tab
}



##' e00Download()-------------
#' download e00 data - code in ice-chart-processing-data-v3 is set to just get e00 files that haven't been downloaded.  If all are desired, see additional code in #
#' @param x = dates
#'
#' @return
#' @export
#'
#' @examples e00Download(x)
e00Download <- function(x){
  for(i in x) {
    fname <- paste0("e00_data/", i, ".e00")
    ftest <- "e00_data/test.e00"
    url.dir <- "http://ice-glaces.ec.gc.ca//www_archive/AOI_12/Coverages/"
    url.file <- paste0("rgc_a12_", i, c("_CEXPREC.e00", "_EXPREC.e00", "_XXXXXX.e00", "_exprec.e00"))
    url <- paste0(url.dir, url.file)
    test <- try(download.file(url[1], ftest))
    if(class(test) == "try-error") {
      test <- try(download.file(url[2], ftest))
      if(class(test) == "try-error") {
        test <- try(download.file(url[3], ftest))
        if(class(test) == "try-error") {
          test <- try(download.file(url[4], ftest))
        }
      }
    }
    if(test == 0) { 
      file.copy(ftest, fname)
    }
  }
}


###########################################################
##' eggAttr.cols()-------------------
## Turn the eggAttr data into columns that can be querried
#'
#' @param x = data, sub.egg object generated by the calcAreaVolume function
#'
#' @return x creates an expanded sub.egg object with with ice data in columns.  Purpose is to provide an easy way to subset egg data with eggAttr.query
#' @examples
## 
eggAttr.cols <- function(x) {
  # do we want to set up the columns first and populate them later?
  egg.cols <- gsub("@", "0", x$EGG_ATTR)
  egg.cols <- gsub("9\\+", "9.5", egg.cols)
  egg.cols <- strsplit(egg.cols, "_")
  egg.cols <- as.data.frame(do.call(rbind, egg.cols))
  colnames(egg.cols) <- c("CT","CA","CB","CC","CD","SO","SA","SB","SC","SD","SE","FA","FB","FC","FD","FE","CS")
  x <- cbind(x, egg.cols)
  return(x)
}


##' eggAttr.query() ---------------
##'query the egg/ice data for concentration and stage among polygons 
#'
#' @param x = data, sub.egg object generated by the calcAreaVolume function and modified by eggAttr.cols(),
#'    CT = total concentration - enter a vectcor, CA = concentration for thickest ice - optional, add others as needed
#'    SA = stage of development of the thickeest ice - enter a vector, SB concentration of second thickest ice - optional, add                          others as needed
#'
#' @return x creates a subset of the sub.egg data
#' @export
#'
#' @examples eggAttr.query(x = data, CT = ct, cA = NULL, SA = sa, SB = NULL)

eggAttr.query <- function(x = data, ct = NULL, sa = NULL, sb = NULL){
  #browser()
  if(is.null(ct)) ct <- unique(x$CT) #if all values of CT are desired
  if(is.null(sa)) sa <- unique(x$SA) #if all values of SA are desired
  if(is.null(sb)) sa <- unique(x$SB) #if all values of SB are desired
  x <- subset(x, subset = CT %in% ct & SA %in% sa | CT %in% ct & SB %in% sb)
  #x <- subset(x, subset = CT %in% ct & SA %in% sa & SB %in% sb)
  #if(nrow(x)==0) {
   #cols <- ncol(x)
    #x[1, ] <- rep(0, cols)
  #}
  #return(x)
}

###########################################################
##' iceSubset()---------------------------------
#'
#' @param x = data, sub.egg object (SPDF) generated by the calcAreaVolume function and modified by eggAttr.cols(),and egg.Attr.query()
#' @param ct = total ice concentration
#' @param sa = icetype
#'
#' @return - sub.egg1 - a subsetted version of sub.egg (SPDF)

#' @export
#'
#' @examples
iceSubset <- function(x, ct = NULL, sa = NULL, sb = NULL) {
  #browser()
  print("inside IS")
  #print(environment())
  #print(ls())
  x@data <- eggAttr.cols(x@data)
  x <- eggAttr.query(x, ct = ct, sa = sa, sb = sb)# try with ....
  
 # y <- subset(x, subset = CT %in% ct & SA %in% sa & SB %in% sb | CT %in% ct & SA %in% sa) # not sure what this line is for
  #y <- subset(x, subset = @data$CT %in% ct & x@data$SA %in% sa & x@data$SB %in% sb)
  #  return(y)
}

###########################################################
## iceTiming ()----------
#'calculate the minimum latitude of ice in a given year - this represents timing of the retreat
#'
#' @param  x = data, sub.egg object (SPDF) generated by the calcAreaVolume function and modified by eggAttr.cols(),and egg.Attr.query()
#'
#' @return tibble object which is a slice of a tidied SPDF with lat and long 
#' @export
#'
#' @examples
#' 
iceTiming <- function(spdf){
  #browser()
  #print("inside IT")
  #print(environment())
  #print(ls())
  d <- tidy(spdf)
  tid <- d[which.min(d$lat),]
  return(tid)
}

##' withinPolyAreaA() ---------------
##' query the egg/ice data for concentration and stage among polygons 
#'
#' @param x = data, sub.egg object generated by the calcAreaVolume function and modified by eggAttr.cols() 
#'
#' @return x creates a subset of the sub.egg data
#' @export
#'
#' @examples
#'
withinPolyAreaA <- function(x = data, ct = NULL, sa = NULL, sb = NULL) {
  #browser()
  print("within1")
  
  for (i in 1:nrow(x)) {
    
    if (is.na(x$SA[i]) | !(x$SA[i] %in% sa)) { # if value of SA = NA, then set AREA_SA to zero
      x$AREA_SA[i] <- 0  # should this be NA????
      
    } else if (x$CA[i] == 0| x$CA[i]=="?"){ # if CA == 0, the below calc won't work - AREA=AREA_SA
      print("CA = 0 or ?")
      x$AREA_SA[i] <- x$AREAice[i] 
      x$CA[i] <- x$CT[i]
      
      # false CD==0 problem - change value of CD according to other values
    } else if (x$CD[i] == 0 & x$SD[i] != 0) { 
      x$CD[i] <- as.numeric(x$CT[i]) - (as.numeric(x$CA[i]) + as.numeric(x$CB[i]) + as.numeric(x$CC[i]))
      x$AREA_SA[i] <- x$AREAice[i] * as.numeric(x$CA[i])/as.numeric(x$CT[i])

      # alter C[X] values to accomodate the CT = 9.5 and CA:CD values sum to 10 or 9		 
    } else if (x$CT[i] == 9.5 & x$CC[i] == 0 & x$CD[i] == 0) {
      
      x$CB[i] <- as.numeric(x$CT[i]) - (as.numeric(x$CA[i]) + as.numeric(x$CC[i]) + as.numeric(x$CD[i]))  
      x$CC[i] <- as.numeric(x$CT[i]) - (as.numeric(x$CA[i]) + as.numeric(x$CB[i]) + as.numeric(x$CD[i]))
      x$CD[i] <- as.numeric(x$CT[i]) - (as.numeric(x$CA[i]) + as.numeric(x$CB[i]) + as.numeric(x$CC[i]))

      x$AREA_SA[i] <- x$AREAice[i] * as.numeric(x$CA[i])/as.numeric(x$CT[i])
    # note that this does not account for the rare times when CT == 9.5 and SD == !0
      # fix this later
      
      # regular	
  } else if (x$CT[i] == 9.5 & x$CD[i] !=0  & x$SD[i] !=0) {

    x$CD[i] <- as.numeric(x$CT[i]) - (as.numeric(x$CA[i]) + as.numeric(x$CB[i]) + as.numeric(x$CC[i]))
    
    x$AREA_SA[i] <- x$AREAice[i] * as.numeric(x$CA[i])/as.numeric(x$CT[i])
    # note that this does not account for the rare times when CT == 9.5 and SD == !0
    # fix this later
    
    # regular	
  } else if (x$CT[i] == 9.5 & x$CD[i] == 0 & x$SD[i] == 0) {
    
    x$CD[i] <- abs(as.numeric(x$CT[i]) - (as.numeric(x$CA[i]) + as.numeric(x$CB[i]) + as.numeric(x$CC[i])))
    
    x$AREA_SA[i] <- x$AREAice[i] * as.numeric(x$CA[i])/as.numeric(x$CT[i])
    # note that this does not account for the rare times when CT == 9.5 and SD == !0
    # fix this later
    
    # regular	
     } else {
    x$AREA_SA[i] <- x$AREAice[i] * as.numeric(x$CA[i])/as.numeric(x$CT[i]) # calculate area for desired values of SA
    }
  }  
  return(x)
}



withinPolyAreaB <- function(x = data, sb = sb) {
  #browser()
  for (i in 1:nrow(x)) {
    if (is.na(x$SB[i]) | !(x$SB[i] %in% sb)) {
      x$AREA_SB[i] <- 0  # if value of SA = NA, then set AREA_SA to zero
      
    } else if(x$CA[i]==0){
      x$AREA_SB[i] <- 0  # if CA == 0, then no values for SB, SC, or SD
    
      } else {
      x$AREA_SB[i] <- x$AREAice[i] * as.numeric(x$CB[i])/as.numeric(x$CT[i]) # calculate area for desired values of SA
    }
  }
  return(x)
}

withinPolyAreaC <- function(x = data, sb = sb) {
  #browser()
  for (i in 1:nrow(x)) {
    if (is.na(x$SC[i]) | !(x$SC[i] %in% sb)) {
      x$AREA_SC[i] <- 0  # if value of SA = NA, then set AREA_SA to zero
    
      } else if(x$CA[i]==0){
      x$AREA_SC[i] <- 0   # if CA == 0, then no values for SB, SC, or SD
    
      } else {
      x$AREA_SC[i] <- x$AREAice[i] * as.numeric(x$CC[i])/as.numeric(x$CT[i]) # calculate area for desired values of SA
    }
  }
  return(x)
}

withinPolyAreaD <- function(x = data, sb = sb) {
  #browser()
  for (i in 1:nrow(x)) {
    if (is.na(x$SD[i]) | !(x$SD[i] %in% sb)) {
      x$AREA_SD[i] <- 0  # if value of SA = NA, then set AREA_SA to zero
      
    } else if(x$CA[i]==0){
      x$AREA_SD[i] <- 0   # if CA == 0, then no values for SB, SC, or SD
      
    } else {
      x$AREA_SD[i] <- x$AREAice[i] * as.numeric(x$CD[i])/as.numeric(x$CT[i]) # calculate area for desired values of SA
    }
  }
  return(x)
}


##' iceArea()-----------------------------
##'uses attribute table to calculate total ice area
#'
#' @param x = data, sub.egg object generated by the calcAreaVolume function and modified by eggAttr.cols(),and egg.Attr.query() and iceSubset()
#'
#' @return x maintains the sub.egg data
#'          icesum - the sum of the ice in the SPDF after the subsets
#' @export
#'
#' @examples
#' 
iceArea <- function(x, ct = NULL, sa = NULL, sb = NULL) {
  #browser()
  x$AREA_SD <- x$AREA_SC <- x$AREA_SB <- x$AREA_SA <- rep(NA, length(x)) 
  x <- withinPolyAreaA(x, ct = ct, sa = sa, sb = sb)
  x <- withinPolyAreaB(x, sb = sb)
  x <- withinPolyAreaC(x, sb = sb)
  x <- withinPolyAreaD(x, sb = sb)
  
  if(nrow(x) == 0){
    print("nrow = 0")
    area <- coverage <- 0    
  } else {
    #area <- x$AREA
    area <- x$AREA_SA + x$AREA_SB + x$AREA_SC + x$AREA_SD
    etab <- eggAttr(x$EGG_ATTR)
    coverage <- as.numeric(gsub("\\+", ".5", etab$E_CT))/10 # convert total coverage to percent
  }
  #sum(area * coverage, na.rm = TRUE)
  icesum <- sum(area, na.rm = TRUE)
  return(list(x, icesum))
}

##' iceVolume()-----------------------------
##' uses attribute table to calculate total ice volume
#' Title Ice Volume
#'
#' @param x 
#'
#' @return
#' @export
#'
#' @examples
iceVolume <- function(x) {
  stab <- data.frame(thick = c(10.0, 10.0, 20.0, 12.5, 22.5, 30.0, 50.0, 40.0, 60.0, 95.0, 120.0),
                     code = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "1.", "4.")) # from table below
  if(nrow(x) == 0){
    vtab <- 0    
  } else {
    area <- x$AREAice
    etab <- eggAttr(x$EGG_ATTR)
    etab$E_CA[is.na(etab$E_CA)] <- etab$E_CT[is.na(etab$E_CA)] # place total concentration in column a if only one ice type
    ct <- as.numeric(gsub("\\+", ".5", etab$E_CT))/10
    ca <- as.numeric(gsub("\\+", ".5", etab$E_CA))/10 # convert coverage to percent
    cb <- as.numeric(gsub("\\+", ".5", etab$E_CB))/10 
    cc <- as.numeric(gsub("\\+", ".5", etab$E_CC))/10 
    cd <- as.numeric(gsub("\\+", ".5", etab$E_CD))/10
    i <- which(is.na(etab$E_CD) & !is.na(etab$E_SD))
    if(length(i) > 0) cd[i] <- ct[i] - (ca[i] + cb[i] + cc[i]) # rule from ice manual
    ta <- stab$thick[match(etab$E_SA, stab$code)] * 1e-5 # thickness converted to km
    tb <- stab$thick[match(etab$E_SB, stab$code)] * 1e-5 # thickness converted to km
    tc <- stab$thick[match(etab$E_SC, stab$code)] * 1e-5 # thickness converted to km
    td <- stab$thick[match(etab$E_SD, stab$code)] * 1e-5 # thickness converted to km
    vtab <- data.frame(a=ca*ta*area, b=cb*tb*area, c=cc*tc*area, d=cd*td*area) # volume table
    vtab[is.na(vtab)] <- 0
    sum(rowSums(vtab))
  }
}

#######################################################################  
##' plotIce()-----------------------------
##' function for plotting ice charts
#'
#' @param x 
#' @param main 
#'
#' @return
#' @export
#'
#' @examples
plotIce <- function(x, main = "") {
  Blues <- colorRampPalette(brewer.pal(8, "Blues"))
  x <- spTransform(x, CRS("+proj=longlat +datum=WGS84"))
  ct <- as.numeric(gsub("\\+", ".5", eggAttr(x$EGG_ATTR)$E_CT))/10
  ct[is.na(ct)] <- 0
  cols <- rgb(1, 1, 1, ct)
  par(mar = c(3, 3, 3, 3), xaxs = "i", yaxs = "i")
  plot(x, axes = TRUE, col = "#084594", border = "#084594", main = main)
  plot(x, col = cols, border = NA, add = TRUE)
  plot(x[x$A_LEGEND == "Land", ], col = "grey60", border = "grey40", lwd = 0.5, add = TRUE)
}


##' e00_to_SpatialPolygonDataframe() ----------------------------------
##' e00 to avc_data (coverages) and then to SpatialPolygonsDAtaframe in sp_data
#'
#' @param x 
#'
#' @return
#' @export
#'
#' @examples

e00_to_SpatialPolygonDataframe <- function(x){
  for(i in x) {
    
    ## names
    e00file <- paste0("e00_data/", i, ".e00")
    spfile <- paste0("sp_data/", i, ".Rdata")
    avcdir <- paste0("avc_data/", i)
    if(!dir.exists(avcdir)) dir.create(avcdir)
    
    ## raw data
    raw <- readLines(e00file) # reads E00 file
    attr.tab <- attrTab(raw) # used attrTab (and eggAttr) functions to make attr.tab
    
    ## get data from  e00 file
    con <- try(e00toavc(e00file, file.path(avcdir, "bin")))
    arc <- try(get.arcdata(avcdir, "bin"))
    pal <- try(get.paldata(avcdir, "bin"))
    pat <- try(get.tabledata(file.path(avcdir, "info"), "bin.PAT")) # get.tablenames(file.path(avcdir, "info"))
    
    if(all(c(class(arc), class(pal)) != "try-error")) {
      
      ## convert data to spatial polygons
      lcc.proj <- "+proj=lcc +lat_1=49 +lat_2=77 +lat_0=40 +lon_0=-100 +x_0=0 +y_0=0 +datum=NAD27 +ellps=clrk66 +units=m +no_defs"
      ice <- pal2SpatialPolygons(arc,
                                 pal,
                                 pal[[1]]$PolygonId[-1],
                                 dropPoly1=TRUE,
                                 proj4string=CRS(lcc.proj))
      
      if(class(pat) != "try-error") {
        ## add table data to make spatial polygons data frame
        dat <- lapply(names(pat), function(i) {
          if(is.character(pat[[i]])) {
            gsub(pattern = "^\\s+|\\s+$", replacement = "", pat[[i]])
          } else {
            pat[[i]]
          }
        })
        dat <- do.call(cbind.data.frame, dat)
        names(dat) <- gsub(" ", "", names(pat))
        dat <- dat[-1, ] # discard first row
        dat[dat == ""] <- NA
        dat$ID <- as.character(seq(nrow(dat)))
      } else {
        ids <- data.frame(ID = sapply(slot(ice, "polygons"), function(x) slot(x, "ID")))
        ids <- na.omit(ids)
        dat <- merge(ids, attr.tab, by = "ID", all.x = TRUE)
        dat <- dat[order(as.numeric(dat$ID)),]
        dat$A_LEGEND[is.na(dat$A_LEGEND)] <- "No data"
        row.names(dat) <- dat$ID
      }
      ice <- try(SpatialPolygonsDataFrame(ice, data = dat))
      try(plotIce(ice, main = i))
      
      ## use cleangeo package to clean-up geometry errors
      ice <- try(clgeo_Clean(ice))
      
      ## save Rdata
      if(class(ice) != "try-error") {
        save(ice, file = spfile)
      }
    }
  }
}




#######################################################
## loadMap()----------------
#' loads maps from Rdata file
#'
#' @param y is a Rdata file
#'
#' @return ice - a Large Spatial Polygon
#' @export
#'
#' @examples ice <- loadMap(y)
loadMap <- function(y){
  #print(y[i])                   #start here when making single object for testing
  load(format(y[i], "sp_data/%Y%m%d.Rdata"))
  return(ice)
}


## subsetProject()------------
#' subset and project to WGS84 (poorly named)
#'
#' @param ice - a Large Spatial Polygon
#'
#' @return egg - a SpatialPolygonDataframe in WGS84
#' @export
#'
#' @examples egg <- subsetProject(ice)
subsetProject <- function(ice){
  #browser()
  egg <- ice[!is.na(ice$EGG_ATTR), ]  # subset
  egg <- spTransform(egg, CRS("+proj=longlat +datum=WGS84")) # convert to WGS84 bc filters are in WGS84 - used on line 460
  return(egg)
}


## filterEgg()------
#' Apply filters and return to lcc projection
#'
#' @param egg - a SpatialPolygonDataframe in WGS84
#'
#' @return sub.egg - a SpatialPolygonDataframe in lcc projection
#' @export
#'
#' @examples sub.egg <- filterEgg(egg)      
filterEgg <- function(egg) {
  #browser()
  attr.tab <- egg@data
  sub.egg <- try(gDifference(egg, filters, byid = TRUE))
  if(class(sub.egg) == "try-error") {
    print("try-error")
    buf.egg <- try(gBuffer(egg, byid = TRUE, width = 0)) # adding a small buffer often fixes geo issues
    sub.egg <- try(gDifference(buf.egg, filters, byid = TRUE)) # remove the egg areas with filters
  }
  if(class(sub.egg) != "try-error" & !is.null(sub.egg)) {
    row.names(attr.tab) <- paste(row.names(attr.tab), "- filters")
    attr.tab <- attr.tab[names(sub.egg), ]
    sub.egg <- SpatialPolygonsDataFrame(sub.egg, attr.tab) # recover data bc of gBuffer and gDifference which make a SP rather than an SPDF
  }
  if(class(sub.egg) == "try-error") { stop("There was a problem applying the filters") }
  return(sub.egg=sub.egg)
}

############################################################
## proceed with area and volume calculations
############################################################
##' calcPolyA()-----------
#' calculates the area of each polygon in SpatailPolygonDataframe
#' # Polgon area != ice area
#' # Polygon area is supplied in raw ice SPDF but is needs to be recalculated because portions of the data are filtered.  Therefore, there is a need to recalculate AREA using the gAREA function resulting in a more robust estiamte of the actual ice area
#' @param z list with subeg`g, minlat, and minlong
#'
#' @return
#' @export z list with subegg, minlat, and minlong and a (used to calculate area)
#'
#' @examples temp.ls <- calcPolyA(temp.ls)
#' temp.ls[[2]]$sub.egg1@data

calcPolyA <- function(z){
  #browser()
  a <- try(gArea(z, byid = TRUE)) # sometimes holes are not identified correctly, so try and extract max polygon area within each id
  if(class(a) == "try-error") { 
    message("gArea didn't work. Trying alternate approach")
    a <- sapply(slot(z, "polygons"), function(x) max(sapply(slot(x, "Polygons"), slot, "area"))) 
  }
  #z$sub.egg1$AREA <- a * 1e-6 # replace polygon area (use square km)
  #temp.ls$a <- a
  
  return(a=a)
}

##' trendsCalc()-------
#' use iceArea() and iceVolume() to calculate the area and volume of ice for specified area
#' @param x  list with subegg, minlat, and minlong and a (used to calculate area)
#'
#' @return list with area, volume, minlat, and minlong for a given date (from Rdata[i])
#' @export
#'
#' @examples calc <- trendsCalc(temp.ls)
trendsCalc <- function(x, y, ct = NULL, sa = NULL, sb = NULL){
  #browser()
  if(class(y) != "try-error") {
    x@data$AREA <- y * 1e-6 # replace polygon area (use square km)
    x@data$AREAice <- x@data$AREA*as.numeric(x@data$CT)/10
    #subarea <- iceArea(x@data)
    subarea <- iceArea(x, ct = ct, sa = sa, sb = sb)
    area <- subarea[[2]]
    volume <- iceVolume(x@data) 
    #minlat <- iceTiming(sub.egg)
    
  }
  return(list(area=area, volume=volume, minlat=x$minlat, minlong=x$minlong))
  
} 


## calcLatLong()------
#' subset the sub.egg data by ice concentration and stage of development and calculate the minimum latitude (timing of iceretreat) using sub functions - needed to proceed with area and volume calculations
#'
#' @param sub.egg a SpatialPolygonDataframe in lcc projection
#' @param ct - total ice concentration
#' @param sa  - stage of ice development for thickest type of ice
#'
#' @return list with subegg, minlat, and minlong
#' @export
#'
#' @examples temp.ls <- calcLatLong(sub.egg, ct = m1$ct, sa = m1$sa)
#' test <- calcLatLong(sub.egg, ct = m2$ct, sa = m2$sa)

calcLatLong <- function(sub.egg, ct = NULL, sa = NULL, sb = NULL) {
  #browser()
  
  sub.egg1 <- iceSubset(sub.egg, ct = ct, sa = sa, sb = sb) 
  
  if(nrow(sub.egg1@data)==0){ # if you subset out all data
    print("subset zero - rows")
    area <- volume <- 0
    minlat <- 55
    minlong <- -56
    #sub.trend <- sp::spTransform(sub.egg, CRS(proj4string(ice)))
    
  } else {
    
    coords_min <- iceTiming(sub.egg1)
    minlat <- coords_min$lat
    minlong <- coords_min$long
    
    ## return to lcc projection and calculate area and volume bc e00 data is in lcc and meters - needed to get proper area/volume calculations
    ice <- get("ice", parent.frame())
    #ice@bbox <- sub.egg1@bbox
    sub.egg1 <- sp::spTransform(sub.egg1, CRS(proj4string(ice)))
    sub.poly <- calcPolyA(sub.egg1)
    sub.trend <- trendsCalc(sub.egg1, sub.poly, ct = ct, sa = sa, sb = sb)
    
    area <- sub.trend$area
    volume <- sub.trend$volume
    minlat <- minlat
    minlong <- minlong
  }
  
  return(list(area=area, volume=volume, minlat=minlat, minlong=minlong))
}

############################################################
# This is the end function - all of the above contribute to this one
############################################################
##' calcAreaVolLat()---------
#' Main function that brings together all the other functions 
#' @param y set of dates
#' @param ct concentration of sea ice
#' @param sa stage of ice development
#'
#' @return a list of areas, volumes, minlats, and minlongs for a series of dates
#' @export
#'
#' @examples test <- calcAreaVolLat(dates3, ct=m1$ct, sa=m1$sa)
#' test <- calcAreaVolLat(dates3[1], ct=m2$ct, sa=m2$sa)
#' test <- calcAreaVolLat(dates3[2], ct=m2$ct, sa=m2$sa)
calcAreaVolLat <- function(y, ct = NULL, sa = NULL, sb = NULL) {
  #browser()
  #my.env <- new.env()
  areas <-
    volumes <-
    minlats <- minlongs <- rep(NA, length(y)) # create an empty object
  for (i in seq_along(y)) {
    ## load map data
    print(y[i])                   #start here when making single object for testing
    load(format(y[i], "sp_data/%Y%m%d.Rdata"))
    ## set area and volume to 0 if no egg attributes
    #print("inside cAVL")
    #print(where("ice"))
    #crs <- CRS("+proj=lcc +lat_1=49 +lat_2=77 +lat_0=40 +lon_0=-100 +x_0=0 +y_0=0 +datum=NAD27")
    #ice <- ice
    if (all(is.na(ice$EGG_ATTR))) {
      print("is NA")
      area <- volume <- 0
      minlat <- 55
      minlong <- -58
    } else {
      egg <- subsetProject(ice)    # ice is not in the local environment
      sub.egg <- filterEgg(egg)
      
      if (is.null(sub.egg)) {
        print("is null")
        area <- volume <- 0
        minlat <- 55 # if NULL, then no ice was below 55 deg North
        minlong <- -57
      } else {
        if (class(sub.egg) != "try-error") {
          calc <- calcLatLong(sub.egg, ct = ct, sa = sa, sb = sb)
          
          
          area <- calc$area
          volume <- calc$volume
          minlat <- calc$minlat
          minlong <- calc$minlong
        } else {
          area <- volume <- minlat <- minlong <-  NA
        }
      }
    }
    
    areas[i] <- area 
    volumes[i] <- volume
    minlats[i] <- minlat
    minlongs[i] <- minlong
  }
  list(
    areas = areas,
    volumes = volumes,
    minlats = minlats,
    minlongs = minlongs
  )
}


############################################################
## Below here are other functions for other work
####################################################################################
##' multiplot()--------- 
#' - like mfrow
#' # Multiple plot function http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)
  
  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)
  
  numPlots = length(plots)
  
  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                     ncol = cols, nrow = ceiling(numPlots/cols))
  }
  
  if (numPlots==1) {
    print(plots[[1]])
    
  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
    
    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
      
      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}


####################################################################################
## PrintLvls() -----------------------------------------------------
# prints levels of an object
# copied from http://r.789695.n4.nabble.com/List-of-Levels-for-all-Factor-variables-td4646355.html
# use this in the Look at Data function to print out levels of all factor variables
PrintLvls <- function(x) {print(data.frame(Lvls=sapply(x[sapply(x,is.factor)],nlevels), 
                                           Names=sapply(x[sapply(x, is.factor)], 
                                                        function(y) paste0(levels(y), collapse=", "))), right=FALSE) 
} 

##' lookAT()--------------------
#' function for printing the head and str of a data set
#' @param x 
#'
#' @return
#' @export
#'
#' @examples - lookAt(iris) # prints head of data set and structure

lookAt <- function(x) {
  print(head(x))
  cat("\n")
  str(x)
  cat("\n")
  cat("Names of levels in Factor Variables")
  cat("\n")
  PrintLvls(x) #see above for code
}

## lookAtSubEgg()   -------------
#' Look At the STructure of a sub.egg object
#'
#' @param z = a vector of dates
#' @param i = a datum in the vector
#'
#' @return an ice object which is in an LCC projection; ice is the unfiltered e00 file in RData form, sub.egg is filtered ice
#' @export
#'
#' @examples
lookAtIce <- function(z, i, ct = NULL, sa = NULL, sb = NULL){
  #browser()
  print(z[i])                   #start here when making single object for testing
  load(format(z[i], "sp_data/%Y%m%d.Rdata"))
  #plotIce(ice, main = dates[i])
  iceLook <- ice
  showIce <- ice@data[, c("AREA", "BIN#", "A_LEGEND", "EGG_ATTR", "E_CT", "E_CA", "E_SA", "E_SB")]
  egg <- subsetProject(ice)    # ice is not in the local environment
  sub.egg <- filterEgg(egg)
  sub.egg1 <- iceSubset(sub.egg, ct = ct, sa = sa, sb = sb) 
  sub.egg1 <- sp::spTransform(sub.egg1, CRS(proj4string(ice)))
  return(list(a=iceLook, b=showIce, c=sub.egg1))
}


extractSubegg1 <- function(z, i, ct = NULL, sa = NULL, sb = NULL){
  #browser()
  print(z[i])                   #start here when making single object for testing
  load(format(z[i], "sp_data/%Y%m%d.Rdata"))
  #plotIce(ice, main = dates[i])
  egg <- subsetProject(ice)    # ice is not in the local environment
  sub.egg <- filterEgg(egg)
  sub.egg1 <- iceSubset(sub.egg, ct = ct, sa = sa, sb = sb) 
  
  sub.egg1 <- sp::spTransform(sub.egg1, CRS(proj4string(ice)))
  out <- iceArea(sub.egg1)
  #sub.poly <- calcPolyA(sub.egg1)
  #sub.trend <- trendsCalc(sub.egg1, sub.poly)
  return(out)
}

extractSPDFfinal <- function(z, i, ct = NULL, sa = NULL, sb = NULL){
  #browser()
  print(z[i])                   #start here when making single object for testing
  load(format(z[i], "sp_data/%Y%m%d.Rdata"))
  #plotIce(ice, main = dates[i])
  egg <- subsetProject(ice)    # ice is not in the local environment
  sub.egg <- filterEgg(egg)
  sub.egg1 <- iceSubset(sub.egg, ct = ct, sa = sa, sb = sb) 
  
  sub.egg1 <- sp::spTransform(sub.egg1, CRS(proj4string(ice)))
  y <- calcPolyA(sub.egg1)
  sub.egg1@data$AREA <- y * 1e-6 # replace polygon area (use square km)
  sub.egg1@data$AREAice <- sub.egg1@data$AREA*as.numeric(sub.egg1@data$CT)/10
  out <- iceArea(sub.egg1, ct=ct, sa=sa, sb=sb)
  return(out)
}

#x@data$AREA <- y * 1e-6 # replace polygon area (use square km)
#x@data$AREAice <- x@data$AREA*as.numeric(x@data$CT)/10
#subarea <- iceArea(x@data)

##################################################################################################### OPtimization funcitons
##  SSQCapelinDome()--------------
### Feb 3 2015 - ADB
### Code to fit the ice capelin model presented in Buren et al 2014
### this is not elegant code, but at the time I ran the nalyses was good enough
### I define 2 functions: one is the objective function SSQCapelinDome   and the second function
### obtains the Expected Log Capelin BIomass (CapelinDome)

### The data must be stored in a dataframe called capelin with at least 3 columns: 'year','tice','logcapelin'
### logcapelin is the observed capelin biomass (in log scale). The data frame capelin cancontain more columns
### NA values of logcapelin (i.e. years when there were no capelin surveys) are not used during optimization

## Objective function - part of optimization function

SSQCapelinDome <- function(params,dataf){
  #browser()
  Alpha <- params[1]
  Beta <- params[2]
  Gamma <- params[3]
  year <- dataf[,1]
  tice <- dataf[,2]
  logcap <- dataf[,3]
  ELogCapBiom <- ifelse(year<1991, Alpha*tice*(1-(tice/Beta)), Alpha*tice*(1-(tice/Beta))*Gamma)
  sum((logcap-ELogCapBiom)^2)
}

SSQCapelinDome1 <- function(params,dataf){
  #browser()
  Alpha <- params[1]
  Beta <- params[2]
  Gamma <- params[3]
  year <- pull(dataf[,1])
  tice <- pull(dataf[,2])
  logcap <- pull(dataf[,3])
  ELogCapBiom <- ifelse(year<1991, Alpha*tice*(1-(tice/Beta)), Alpha*tice*(1-(tice/Beta))*Gamma)
  sum((logcap-ELogCapBiom)^2)
}

## Function to obtain Expected Log Capelin Biomass         
CapelinDome <- function(params,dataf){
  Alpha <- params[1]
  Beta <- params[2]
  Gamma <- params[3]
  year <- dataf[,1]
  tice <- dataf[,2]
  ELogCapBiom <- ifelse(year<1991, Alpha*tice*(1-(tice/Beta)), Alpha*tice*(1-(tice/Beta))*Gamma)
  ELogCapBiom
}

CapelinDome1 <- function(params,dataf){
  Alpha <- params[1]
  Beta <- params[2]
  Gamma <- params[3]
  year <- pull(dataf[,1])
  tice <- pull(dataf[,2])
  ELogCapBiom <- ifelse(year<1991, Alpha*tice*(1-(tice/Beta)), Alpha*tice*(1-(tice/Beta))*Gamma)
  ELogCapBiom
}

#####################################################################################################
##' modelGraphs()-------------
#' figure for plotting predicted values of models over a range of years
#' @param x = years
#'
#' @return graphs from 1970-2016 (or based on vector)
#' @export
#'
#' @examples modelGraphs(years)
modelGraphs <- function(years){
  for(i in seq_along(years)) {
    
    ## subset data
    mod.dat <- trends[year == years[i]]
    mod.dat$t <- mod.dat$doy
    mod.dat$a <- mod.dat$area/1000
    mod.p <- ggplot(mod.dat) + 
      geom_point(aes(x = t, y = a)) + 
      theme_bw() + 
      xlab('Day of Year (NOV - JUL)') +
      ylab('Area') +
      theme(panel.grid.major = element_line(linetype = "dotted")) # make base layer and plot data
    
    
    ## extract basic parameters
    raw.amax[i] <- max(mod.dat$a)
    raw.tmax[i] <- mod.dat$t[which.max(mod.dat$a)]
    
    ## approx start vals
    j <- which(mod.dat$a > quantile(mod.dat$a, prob = 0.50)) # top values
    h <- max(mod.dat$a[j]) / sqrt(2 * pi)
    s <- max(mod.dat$t[j]) - min(mod.dat$t[j])
    tm <- mean(mod.dat$t[j])
    # b <- h/tm
    
    ## run models
    mod1 <- try(nls(a ~ (h / sqrt(2 * pi)) * (exp(-((t - tm) ^ 2) / (2 * s ^ 2))), 
                    data = mod.dat, 
                    start = list(h = h, s = s, tm = tm),
                    lower = c(0, 0, -60), # except for tm (let search back to Nov 1 [doy -60]), constrain to positive parameter space 
                    control = nls.control(maxiter = 100), 
                    algorithm = "port"))
    mod2 <- try(nls(a ~ (h / sqrt(2 * pi)) * (exp(-((t - tm) ^ 2) / (2 * ifelse(t < tm, s1, s2) ^ 2))),  # see http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2993707/   
                    data = mod.dat, 
                    start = list(h = h, s1 = s/2, s2 = s/2, tm = tm),
                    lower = c(0, 0, 0, -60), # except for tm (let search back to Nov 1 [doy -60]), constrain to positive parameter space
                    control = nls.control(maxiter = 100),
                    algorithm = "port"))
    
    if(class(mod1) != "try-error" | class(mod2) != "try-error") {
      
      ## predict
      preds <- data.frame(t = min(mod.dat$t):max(mod.dat$t))
      if(class(mod1) != "try-error") preds$mod1 <- predict(mod1, newdata = preds)
      if(class(mod2) != "try-error") preds$mod2 <- predict(mod2, newdata = preds)
      preds <- data.table(preds)
      preds <- melt(preds, id.var = "t", variable.name = "mod", value.name = "a")
      
      if(class(mod2) != "try-error") {
        amax[i] <- coefficients(mod2)["h"] / sqrt(2 * pi)
        tmax[i] <- coefficients(mod2)["tm"]
        tstart[i] <- coefficients(mod2)["tm"] - sqrt(-2 * log(0.20)) * coefficients(mod2)["s1"] # start of advance (20% of amax)
        tend[i] <- coefficients(mod2)["tm"] + sqrt(-2 * log(0.20)) * coefficients(mod2)["s2"] # end of retreat (20% of amax)
        adv.mag[i] <- coefficients(mod2)["h"] * coefficients(mod2)["s1"] / 2
        ret.mag[i] <- coefficients(mod2)["h"] * coefficients(mod2)["s2"] / 2
        #round(mod.amax[i] * 0.20, 3) == round(predict(mod2, newdata = data.frame(t = ret.end[i])), 3) # check math
        ## calculate advance and retreat maginitude
        
        x <- c(tmax[i], tstart[i], tend[i])
        y <- predict(mod2, newdata = data.frame(t = x))
        seg.df <- data.frame(x1 = x, x2 = x, y1 = rep(0, length(y)), y2 = y)
        mod.p <- mod.p + 
          #geom_ribbon(aes(x = t, ymin = 0, ymax = a), 
          #                           data = preds[mod == "mod2"],
          #                           fill = "#00BFC4", alpha = 0.15) +
          geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2), 
                       data = seg.df, linetype = "dashed", col = "#00BFC4") +
          geom_hline(yintercept = amax[i], linetype = "dashed", col = "#00BFC4") # plots intersection - not sure of what yet
      }
      
      ## add prediction to plot 
      mod.p <- mod.p + 
        geom_line(aes(x = t, y = a, col = mod), preds, size = 0.7) # plots the predicted values 
      #labs(mod = "Model") #- tried to change the legend
      
      #scale_fill_continuous(guide = guide_legend(title = "Model"))  
    }
    
    ## print plot and clean-up
    print(mod.p + ggtitle(years[i])) # add the years
    rm(mod1, mod2)
    
  }
}


############################################################
##' iceMedian()---------------
#'
#' @param df the output of ice-chart-processing-data (e.g. trends.m1) and data1 is output from iceSummary()
#' @return a list of:
#' 1) the subsetted data
#' 2) the median values of minlats, tice, and area
#' 3) combines 2) with the values of iceSummary()
#' @export
#'
#' @examples sub1991 <- iceMedian(trends.m1, "year < 1992", "tice < 150", iceSum.m1)
iceMedian <- function(df, subset_yr, subset_ti, data1) {
  #browser()
  #print(yr)
  #print(ti)
  df1 <- subset(df, eval(parse(text = subset_yr)) & eval(parse(text = subset_ti)))
  #df1 <- subset(df, paste("year", operator1, yr) & tice < ti)
  #df1 <- subset(df, do.call(operator1, list(get(year), yr)))
  #print(df1)
  
  df2 <- df1 %>%
    group_by(year) %>%
    summarize(dminlats = median(minlats))
  
  df3 <- df1 %>%
    group_by(year) %>%
    summarize(dtice = median(tice))
  
  df4 <- df1 %>%
    group_by(year) %>%
    summarize(darea = median(area))

  df5 <- left_join(df2, df3, by = "year")
  df5 <- left_join(df5, df4, by = "year")
  
  df6 <- subset(data1, eval(parse(text = subset_yr)))
  df7 <- left_join(df6, df5, by = "year")
  
  return(list(data = df1, meds=df5, mall=df7))
}

##################################################################
##' iceSummary()-----
#'
#' @param df the output of ice-chart-processing-data (e.g. trends.m1)
#'
#' @return a dataframe with the max of iceArea and minLat for a given year
#' @export
#'
#' @examples iceSum.m1 <- iceSummary(trends.m1)
iceSummary <- function(df){
  #browser()
  ##modify trends
  # add year
  df$year <- year(df$date)
  #convert date.y to doy
  df$jday <- yday(df$date)
  
  # calculate the maximum area for ice by year
  df1 <- df[c("date", "area", "volume", "year", "jday")]
  temp1 <- df1 %>%
    filter(jday <= 150) %>%
    group_by(year) %>%
    slice(which.max(area)) 
  temp1 

  # calculate the minimum latitude for ice by year
  df2 <- df[c("date", "minlats", "minlongs", "year", "jday")]
  temp2 <- df2 %>%
    filter(jday <= 150) %>%
    group_by(year) %>%
    slice(which.min(minlats)) 
  
  # merge summarized dataframes
  df1 <- full_join(temp1, temp2, by = "year")
  
  #convert date.y to doy
  df1$tice <- yday(df1$date.y)
  return(df1)
}

##################################################################
##' iceMedianD5()-------
#'
#' @param df the output of ice-chart-processing-data (e.g. trends.m1)
#'
#' @return the median values of minlats, tice, and area for the top 5 values
#' @export
#'
#' @examples
iceMedianD5 <- function(df, subset_yr, subset_ti, data1){
  #browser()
  df1 <- subset(df, eval(parse(text = subset_yr)) & eval(parse(text = subset_ti)))
  
  t1 <- df1 %>%
    group_by(year) %>%
    arrange(desc(area)) %>%
    slice(1:5) %>%
    summarize(d5area=median(area))

  t2 <- df1 %>%
    group_by(year) %>%
    arrange(minlats) %>%
    slice(1:5) %>%
    summarize(d5tice=median(tice))

  t3 <- df1 %>%
    group_by(year) %>%
    arrange(minlats) %>%
    slice(1:5) %>%
    summarize(d5minlats=median(minlats))
  
  df2 <- left_join(t1, t2, by = "year")
  df2 <- left_join(df2, t3, by = "year")
  
  df3 <- subset(data1, eval(parse(text = subset_yr)))
  df4 <- left_join(df3, df2, by = "year")
  return(list(data = df1, meds=df2, mall=df4))
}


##################################################################
##' subsetTestPlot()------
#'
#' @param df1 results of model 1
#' @param df2 results of model 2
#' @param date the date which is used to merge the datasets
#'
#' @return a graph of the two datasets with an abline - no values should be above the line
#' @export
#'
#' @examples
subsetTestPlot <- function(df1, df2, date){
  mtest <- merge(df1, df2, by = eval(parse(text = date)))
  plot(mtest$area.x, mtest$area.y)
  abline(a=0, b = 1, col="red", lwd=3)  
}

##################################################################
##' iceSummarylm()------------
#'
#' @param dataframe 
#'
#' @return - list of lm summaries
#' @export
#'
#' @examples iceSummarylm (sub2017.m1)
iceSummarylm <- function(df, med = NULL, med1 = NULL) {
  #browser()
  a <- summary(lm(paste0(med, "minlats", " ~ ", med1, "area"), data=df$mall))
  b <- summary(lm(paste0(med, "minlats", " ~ ", med, "tice"), data=df$mall))
  c <- summary(lm(paste0(med1, "area", " ~ ", med, "tice"), data=df$mall))  
  return(list(minlats_v_area = a, minlats_v_tice = b, area_v_tice = c))
}


##################################################################
##' iceDateScatter()--------
#'
#' @param df 
#'
#' @return 1 graphs of date v minlats, and 2 faceted histograms of minlats by date
#' @export
#'
#' @examples
#' 
iceDateScatter <- function(df, d = NULL){
  #browser()
p1 <- ggplot(data = df$data, aes(x = date, y = minlats)) + 
  geom_point() + 
  geom_smooth(method=lm)
  
p2 <-   ggplot(data = df$data, aes(minlats)) + 
    geom_histogram() + 
    facet_wrap(~ year) +
    geom_vline(data = df$mall, aes_string(xintercept = paste0(d, "minlats")), colour = "red")
  
p3 <- ggplot(data = df$data, aes(area)) + 
    geom_histogram(bins = 10) + 
    facet_wrap(~ year) +
    geom_vline(data = df$mall, aes_string(xintercept = paste0(d, "area")), colour = "red")
  return(list(p1=p1, p2=p2, p3=p3))
}

##################################################################
#' iceYearBox()----------
#'
#' @param df1 
#' @param df2 
#' @param df3 
#'
#' @return
#' @export
#'
#' @examples
iceYearBox <- function(df1, df2, df3, df4) {
  p1 <- ggplot(data = df1, aes(x = year, y = area, group = year)) + 
    geom_boxplot()
  p2 <- ggplot(data = df1, aes(x = year, y = minlats, group = year)) + 
    geom_boxplot()
  p3 <- ggplot(data = df2, aes(x = year, y = area, group = year)) + 
    geom_boxplot()
  p4 <- ggplot(data = df2, aes(x = year, y = minlats, group = year)) + 
    geom_boxplot()
  p5 <- ggplot(data = df3, aes(x = year, y = area, group = year)) + 
    geom_boxplot()
  p6 <- ggplot(data = df3, aes(x = year, y = minlats, group = year)) + 
    geom_boxplot()
  p7 <- ggplot(data = df4, aes(x = year, y = area, group = year)) + 
    geom_boxplot()
  p8 <- ggplot(data = df4, aes(x = year, y = minlats, group = year)) + 
    geom_boxplot()
  windows()
  multiplot(p1, p3, p5, p7, p2, p4, p6, p8, cols=2)
}


##################################################################
#' Title
#'
#' @param df 
#' @param reg1 
#' @param reg2 
#' @param yearInt 
#' @param lnbiomassInt 
#'
#' @return
#' @export
#'
#' @examples
optimGraphs <- function(df, reg1, reg2, yearInt, lnbiomassInt){
  
  p1 <- ggplot(df, aes(x = year, y = logcapelin)) + 
    geom_errorbar(width = 0.3, colour = "black", aes(ymin=logcapelinlb, ymax=logcapelinub)) + 
    geom_point(shape=16, size=3)  +
    geom_line(aes(y=ExpectedLogBiomass), colour="red", linetype=1, size=1.25) +
    geom_line(aes(y=ExpectedLogBiomassOld), colour="blue", linetype=1, size=1.25) +
    scale_y_continuous(limits = c(0,10), breaks = lnbiomassInt) +
    scale_x_continuous(limits = c(1982,2018), breaks = yearInt) +
    xlab('Year') +
    ylab('ln (Capelin biomass (ktons))') + 
    theme_bw()
  
  p2 <- ggplot(df, aes(x = year, y = capelin)) +
    geom_errorbar(width = 0.3, colour = "black", aes(ymin=capelinlb, ymax=capelinub)) + 
    geom_point(shape=16, size=3)  +
    geom_line(aes(y=exp(ExpectedLogBiomass)), colour="red", linetype=1, size=1.25) +
    geom_line(aes(y=exp(ExpectedLogBiomassOld)), colour="blue", linetype=1, size=1.25) +
    #scale_y_continuous(limits = c(0,8500), breaks = biomassInt) +
    scale_x_continuous(limits = c(1982,2018), breaks = yearInt) +
    xlab('Year') +
    ylab('Capelin biomass (ktons)') + 
    theme_bw() +
    annotate("text", x = 2008, y = 8400, label = "Model estimates to 2014") + # all following for the legend
    annotate("text", x = 2008, y = 8000, label = "Model estimates to 2010") +
    annotate("segment", x = 2001, xend = 2003, y = 8400, yend = 8400, colour = "red") +
    annotate("segment", x = 2001, xend = 2003, y = 8000, yend = 8000, colour = "blue")
  
  
  p3 <- ggplot() +
    geom_line(data = reg1, aes(x = tice, y = ExpectedLogBiomass), colour="red", linetype=1, size=1.25) + 
    geom_line(data = reg2, aes(x = tice, y = ExpectedLogBiomass), colour="red", linetype=1, size=1.25) +
    geom_line(data = reg1, aes(x = tice, y = ExpectedLogBiomassOld), colour="blue", linetype=1, size=1.25) +
    geom_line(data = reg2, aes(x = tice, y = ExpectedLogBiomassOld), colour="blue", linetype=1, size=1.25) +
    geom_point(data = subset(df, year < 1991), aes(x = tice, y = logcapelin), shape=2, size=3) +
    geom_point(data = subset(df, year > 1991), aes(x = tice, y = logcapelin), shape=15, size=3) + 
    geom_errorbar(data = subset(df, year < 1991), aes(x = tice, ymin=logcapelinlb, ymax=logcapelinub), width = 0.3, colour = "black") +
    geom_errorbar(data = subset(df, year > 1991), aes(x = tice, ymin=logcapelinlb, ymax=logcapelinub), width = 0.3, colour = "black") +
    xlab("labtice") +
    ylab("ln (Capelin biomass (ktons))") + 
    ylim(0,9) +
    theme_bw()
  
  # make multiplot
  #pdf('ice-capelin-update-2014-new.pdf',height=9,width=9,pointsize =8)
  multiplot(p1, p3, p2, cols=2)
  #dev.off()
  
}
# make optimization graphs by year and in comparison to ice

##################################################################
##' iceScatterSummary()--------
#'
#' @param df 
#'
#' @return 1 graphs of date v minlats, and 2 faceted histograms of minlats by date
#' @export
#'
#' @examples
#' 
iceScatterSummary <- function(df){
  #browser()
  p1.m1  <- ggplot(data = df, aes(x = area, y = tice)) + geom_point() + geom_smooth(method=lm)
  s1 <- summary(lm(tice~area, data=df))
  
  # plot tice against ice area
  p2.m1 <- ggplot(data = df, aes(x = minlats, y = tice)) + geom_point() + geom_smooth(method=lm)
  s2 <- summary(lm(tice~minlats, data=df))
  
  #plot ice area against minlats
  p3.m1 <- ggplot(data = df, aes(x = area, y = minlats)) + geom_point() + geom_smooth(method=lm)
  s3 <- summary(lm(minlats~area, data=df))
  
  return(list(s1=s1, s2=s2, s3=s3, p1=p1, p2=p2, p3=p3))
}