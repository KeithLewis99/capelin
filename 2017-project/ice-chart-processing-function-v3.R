################################################################
#  Script written by Paul Regular (Paul.Regular@dfo-mpo.gc.ca)  #
#  Created 201X-XX-XX, R version 3.X.x (201X-XX-XX)             #
#  Last modified by Paul Regular, Alejandro Buren, and Keith Lewis 2017-07.04 #
#  See Ale's optimization functions at the end
################################################################

# The purpose of this file is to store the funcitons required for:
#1) eggAttr(): function for extracting egg attributes from EGG_ATTR string
#2) attrTab(): extracting attribute table from raw e00 file (not 100% successful)
#3) e00Download(): download e00 data from environment Canada - see function for notes
#4) eggAttr.cols(): Turn the eggAttr data into columns that can be querried
#5) eggAttr.query(): query the egg/ice data for concentration and stage among polygons 
#6) iceSubset(): sub.egg object (SPDF) generated by the calcAreaVolume function and modified by eggAttr.cols(),and egg.Attr.query()
#7) iceTiming (): calculate the minimum latitude of ice in a given year - this represents timing of the retreat
#8) withinPolyAreaA(): query the egg/ice data for concentration and stage among polygons (could not generalize this so 4 functions instead of one)
#9) iceArea(): using the attribute table to calculate total ice area
#10) iceVolume(): using attribute table to calculate total ice volume
#11) plotIce: function for plotting ice charts 
#12) e00_to_SpatialPolygonDataframe(): e00 to avc_data (coverages) and then to SpatialPolygonsDAtaframe in sp_data
#13) loadMap(): loads maps from Rdata file
#14) subsetProject(): subset and project to WGS84 (poorly named)
#15) filterEgg(): Apply filters and return to lcc projection
#16) calcLatLong(): subset the sub.egg data by ice concentration and stage of development and calculate the minimum latitude (timing of iceretreat) using sub functions - needed to proceed with area and volume calculations
#17) calcPolyA(): calculates the area of each polygon in SpatailPolygonDataframe
#18) trendsCalc(): use iceArea() and iceVolume() to calculate the area and volume of ice for specified area
#19) calcAreaVolLat(): Main function that brings together all the other functions
#20) multiplot
#21) several lookat functions
#22) Ale's optimization functions


#) LookAt function


# V1 - first attempt at taking Paul's code and making functions
# v2 - add functions to subset ice
# v3 - a substantial reworking of the file - the calcAreaVol() was reworked into calcAreaVolLat() and was broken up into multiple subfunctions
## Custom functions 

##' eggAttr()-----------------------------
##' function for extracting egg attributes from EGG_ATTR string - used in iceArea() to elegantly extract values from the EGG_ATTR string and calculate area
#' Egg data Attributes
#'
#' @param x where x is an object
#'
#' @return
#' @export
#'
#' @examples
#' 
eggAttr <- function(x) {
  if(any(grepl("_", x))) {
    sx <- strsplit(x, "_")
  } else {
    sx <- vector("list", length(x))
  }
  sx <- lapply(sx, function(i) {
    newi <- i
    if (length(i) == 0) {
      newi <- rep(NA, 17)
    } else {
      newi[newi == "@" | newi == "X"] <- NA
    }
    newi
  }
  )
  sx <- data.frame(do.call(rbind, sx))
  names(sx) <- c("E_CT","E_CA","E_CB","E_CC","E_CD","E_SO","E_SA","E_SB","E_SC","E_SD","E_SE","E_FA","E_FB","E_FC","E_FD","E_FE","E_CS")
  sx
}

##' attrTab()-----------------------------
##' function for extracting attribute table from raw e00 file (not 100% successful)
#' Attribute Table
#'
#' @param x = data 
#'
#' @return
#' @export
#'
#' @examples
attrTab <- function(x) {
  
  full.pattern <- c("Land", "No data", "Ice free", "Open water", 
                    "Fast ice", "Remote egg", "Bergy water", "Egg")
  partial.pattern <- c("Land", "No", "Ice", "Open", 
                       "Fast", "Remote", "Bergy", "Egg")
  p <- paste(partial.pattern, collapse = "|")
  i <- grep(p, x) # find matches to A_LEGEND types
  subx <- x[head(i, 1):tail(i, 1)]
  subi <- grep(p, subx) # revise i
  id <- aleg <- egg.attr <- rep(NA, length(subi))
  for(i in seq_along(subi)) {
    j <- regexpr(p, subx[subi[i]])
    aleg[i] <- regmatches(subx[subi[i]], j)
    id[i] <- as.integer(substr(subx[subi[i]], j-3, j-1)) # polygon id usually 3 characters before A_LEGEND text
    e <- paste(subx[subi[i]+1:2], collapse = "") # looks like EGG_ATTR text is 1-2 records ahead of A_LEGEND text
    if(grepl("_@_", e)) {
      j <- gregexpr("_", e)
      e <- substr(e, max(j[[1]])-35, max(j[[1]])+3)
      egg.attr[i] <- gsub("^\\s+|\\s+$", "", e) # clear spaces
    } else {
      egg.attr[i] <- NA
    }
  }
  attr.tab <- data.frame(ID = id, A_LEGEND = aleg, EGG_ATTR = egg.attr)
  attr.tab <- attr.tab[!is.na(attr.tab$ID), ] # chuck records missing id
  attr.tab <- attr.tab[!duplicated(attr.tab$ID), ] # remove duplicate IDs
  attr.tab <- cbind(attr.tab, eggAttr(attr.tab$EGG_ATTR)) # split egg attributes and add 
  attr.tab$A_LEGEND[is.na(attr.tab$A_LEGEND)] <- "No data"
  attr.tab$A_LEGEND <- full.pattern[match(attr.tab$A_LEGEND, partial.pattern)]
  row.names(attr.tab) <- attr.tab$ID
  attr.tab
}



##' e00Download()-------------
#' download e00 data - code in ice-chart-processing-data-v3 is set to just get e00 files that haven't been downloaded.  If all are desired, see additional code in #
#' @param x = dates
#'
#' @return
#' @export
#'
#' @examples e00Download(x)
e00Download <- function(x){
  for(i in x) {
    fname <- paste0("e00_data/", i, ".e00")
    ftest <- "e00_data/test.e00"
    url.dir <- "http://ice-glaces.ec.gc.ca//www_archive/AOI_12/Coverages/"
    url.file <- paste0("rgc_a12_", i, c("_CEXPREC.e00", "_EXPREC.e00", "_XXXXXX.e00", "_exprec.e00"))
    url <- paste0(url.dir, url.file)
    test <- try(download.file(url[1], ftest))
    if(class(test) == "try-error") {
      test <- try(download.file(url[2], ftest))
      if(class(test) == "try-error") {
        test <- try(download.file(url[3], ftest))
        if(class(test) == "try-error") {
          test <- try(download.file(url[4], ftest))
        }
      }
    }
    if(test == 0) { 
      file.copy(ftest, fname)
    }
  }
}


###########################################################
##' eggAttr.cols()-------------------
## Turn the eggAttr data into columns that can be querried
#'
#' @param x = data, sub.egg object generated by the calcAreaVolume function
#'
#' @return x creates an expanded sub.egg object with with ice data in columns.  Purpose is to provide an easy way to subset egg data with eggAttr.query
#' @examples
## 
eggAttr.cols <- function(x) {
  # do we want to set up the columns first and populate them later?
  egg.cols <- gsub("@", "0", x$EGG_ATTR)
  egg.cols <- gsub("9\\+", "9.5", egg.cols)
  egg.cols <- strsplit(egg.cols, "_")
  egg.cols <- as.data.frame(do.call(rbind, egg.cols))
  colnames(egg.cols) <- c("CT","CA","CB","CC","CD","SO","SA","SB","SC","SD","SE","FA","FB","FC","FD","FE","CS")
  x <- cbind(x, egg.cols)
  return(x)
}


##' eggAttr.query() ---------------
##'query the egg/ice data for concentration and stage among polygons 
#'
#' @param x = data, sub.egg object generated by the calcAreaVolume function and modified by eggAttr.cols(),
#'    CT = total concentration - enter a vectcor, CA = concentration for thickest ice - optional, add others as needed
#'    SA = stage of development of the thickeest ice - enter a vector, SB concentration of second thickest ice - optional, add                          others as needed
#'
#' @return x creates a subset of the sub.egg data
#' @export
#'
#' @examples eggAttr.query(x = data, CT = ct, cA = NULL, SA = sa, SB = NULL)

eggAttr.query <- function(x = data, ct = NULL, sa = NULL){
  if(is.null(ct)) ct <- unique(x$CT) #if all values of CT are desired
  if(is.null(sa)) sa <- unique(x$SA) #if all values of SA are desired
  x <- subset(x, subset = CT %in% ct & SA %in% sa)
  if(nrow(x)==0) {
    cols <- ncol(x)
    x[1, ] <- rep(0, cols)
  }
  return(x)
}

###########################################################
##' iceSubset()---------------------------------
#'
#' @param x = data, sub.egg object (SPDF) generated by the calcAreaVolume function and modified by eggAttr.cols(),and egg.Attr.query()
#' @param ct = total ice concentration
#' @param sa = icetype
#'
#' @return - sub.egg1 - a subsetted version of sub.egg (SPDF)

#' @export
#'
#' @examples
iceSubset <- function(x, ct = NULL, sa = NULL) {
  #browser()
  print("inside IS")
  #print(environment())
  #print(ls())
  x@data <- eggAttr.cols(x@data)
  x@data <- eggAttr.query(x@data, ct = ct, sa = sa)# try with ....
  
  y <- subset(x, subset = CT %in% ct & SA %in% sa)
  #  return(y)
}

###########################################################
## iceTiming ()----------
#'calculate the minimum latitude of ice in a given year - this represents timing of the retreat
#'
#' @param  x = data, sub.egg object (SPDF) generated by the calcAreaVolume function and modified by eggAttr.cols(),and egg.Attr.query()
#'
#' @return tibble object which is a slice of a tidied SPDF with lat and long 
#' @export
#'
#' @examples
#' 
iceTiming <- function(spdf){
  #browser()
  #print("inside IT")
  #print(environment())
  #print(ls())
  d <- tidy(spdf)
  tid <- d[which.min(d$lat),]
  return(tid)
}

##' withinPolyAreaA() ---------------
##' query the egg/ice data for concentration and stage among polygons 
#'
#' @param x = data, sub.egg object generated by the calcAreaVolume function and modified by eggAttr.cols() 
#'
#' @return x creates a subset of the sub.egg data
#' @export
#'
#' @examples
withinPolyAreaA <- function(x = data) {
  #browser()
  print("within1")
  for (i in 1:nrow(x)) {
    if (is.na(x$SA[i])) {
      x$AREA_SA[i] <- 0  # if value of SA = NA, then set AREA_SA to zero
    
      } else if (x$CA[i]==0){
      x$AREA_SA[i] <- x$AREA[i] # if CA == 0, the below calc won't work - AREA=AREA_SA
    
      } else if(as.numeric(x$CA[i]) + as.numeric(x$CB[i]) + as.numeric(x$CC[i]) ==10){
      x$AREA_SA[i] <- x$AREA[i] * as.numeric(x$CA[i])/10 # if CA-D values == 10
    
      } else if (x$CD[i] == 0 & x$SD[i] != 0) {
        x$CD[i] <- 1 # is this right?  Should it not be CT - (CA + CB + CC)
        x$CT[i] <- as.numeric(x$CA[i]) + as.numeric(x$CB[i]) + as.numeric(x$CC[i]) + as.numeric(x$CD[i])
        x$AREA_SA[i] <- x$AREA[i] * as.numeric(x$CA[i])/as.numeric(x$CT[i])

      } else {
      x$AREA_SA[i] <- x$AREA[i] * as.numeric(x$CA[i])/as.numeric(x$CT[i]) # calculate area for desired values of SA
    }
  }
  return(x)
}

withinPolyAreaB <- function(x = data) {
  #browser()
  for (i in 1:nrow(x)) {
    if (is.na(x$SB[i])) {
      x$AREA_SB[i] <- 0  # if value of SA = NA, then set AREA_SA to zero
      
    } else if(x$CA[i]==0){
      x$AREA_SB[i] <- 0  # if CA == 0, then no values for SB, SC, or SD
    
      } else if(as.numeric(x$CA[i]) + as.numeric(x$CB[i]) + as.numeric(x$CC[i]) ==10){
      x$AREA_SB[i] <- x$AREA[i] * as.numeric(x$CB[i])/10 # calculate
    
      } else if (x$CD[i] == 0 & x$SD[i] != 0) {
        x$CD[i] <- 1
        x$CT[i] <- as.numeric(x$CA[i]) + as.numeric(x$CB[i]) + as.numeric(x$CC[i]) + as.numeric(x$CD[i])
        x$AREA_SB[i] <- x$AREA[i] * as.numeric(x$CD[i])/as.numeric(x$CT[i])
      
      } else {
      x$AREA_SB[i] <- x$AREA[i] * as.numeric(x$CB[i])/as.numeric(x$CT[i]) # calculate area for desired values of SA
    }
  }
  return(x)
}


withinPolyAreaC <- function(x = data) {
  #browser()
  for (i in 1:nrow(x)) {
    if (is.na(x$SC[i])) {
      x$AREA_SC[i] <- 0  # if value of SA = NA, then set AREA_SA to zero
    
      } else if(x$CA[i]==0){
      x$AREA_SC[i] <- 0   # if CA == 0, then no values for SB, SC, or SD
    
      } else if(as.numeric(x$CA[i]) + as.numeric(x$CB[i]) + as.numeric(x$CC[i]) ==10){
      x$AREA_SC[i] <- x$AREA[i] * as.numeric(x$CC[i])/10 # calculate
    
      } else if (x$CD[i] == 0 & x$SD[i] != 0) {
        x$CD[i] <- 1
        x$CT[i] <- as.numeric(x$CA[i]) + as.numeric(x$CB[i]) + as.numeric(x$CC[i]) + as.numeric(x$CD[i])
        x$AREA_SC[i] <- x$AREA[i] * as.numeric(x$CD[i])/as.numeric(x$CT[i])
        
      } else {
      x$AREA_SC[i] <- x$AREA[i] * as.numeric(x$CC[i])/as.numeric(x$CT[i]) # calculate area for desired values of SA
    }
  }
  return(x)
}


withinPolyAreaD <- function(x = data) {
  #browser()
  for (i in 1:nrow(x)) {
    if (is.na(x$SD[i])) {
      x$AREA_SD[i] <- 0  # if value of SA = NA, then set AREA_SA to zero
      
    } else if(x$CA[i]==0){
      x$AREA_SD[i] <- 0   # if CA == 0, then no values for SB, SC, or SD
      
    } else if(as.numeric(x$CA[i]) + as.numeric(x$CB[i]) + as.numeric(x$CC[i]) == 10){
      x$AREA_SD[i] <- x$AREA[i] * as.numeric(x$CD[i])/10 # calculate
      
    } else if (x$CD[i] == 0 & x$SD[i] != 0) {
      x$CD[i] <- 1
      x$CT[i] <- as.numeric(x$CA[i]) + as.numeric(x$CB[i]) + as.numeric(x$CC[i]) + as.numeric(x$CD[i])
      x$AREA_SD[i] <- x$AREA[i] * as.numeric(x$CD[i])/as.numeric(x$CT[i])
      
    } else {
      x$AREA_SD[i] <- x$AREA[i] * as.numeric(x$CD[i])/as.numeric(x$CT[i]) # calculate area for desired values of SA
    }
  }
  return(x)
}



##' iceArea()-----------------------------
##'uses attribute table to calculate total ice area
#'
#' @param x = data, sub.egg object generated by the calcAreaVolume function and modified by eggAttr.cols(),and egg.Attr.query() and iceSubset()
#'
#' @return x maintains the sub.egg data
#'          icesum - the sum of the ice in the SPDF after the subsets
#' @export
#'
#' @examples
#' 
iceArea <- function(x) {
  #browser()
  #x$AREA_SA <- x$AREA_SB <- x$AREA_SC <- x$AREA_SD <- rep(NA, length(x)) 
  x <- withinPolyAreaA(x)
  x <- withinPolyAreaB(x)
  x <- withinPolyAreaC(x)
  x <- withinPolyAreaD(x)
  
  if(nrow(x) == 0){
    print("nrow = 0")
    area <- coverage <- 0    
  } else {
    #area <- x$AREA
    area <- x$AREA_SA + x$AREA_SB + x$AREA_SC + x$AREA_SD
    etab <- eggAttr(x$EGG_ATTR)
    coverage <- as.numeric(gsub("\\+", ".5", etab$E_CT))/10 # convert total coverage to percent
  }
  #sum(area * coverage, na.rm = TRUE)
  icesum <- sum(area, na.rm = TRUE)
  return(list(x, icesum))
}

##' iceVolume()-----------------------------
##' uses attribute table to calculate total ice volume
#' Title Ice Volume
#'
#' @param x 
#'
#' @return
#' @export
#'
#' @examples
iceVolume <- function(x) {
  stab <- data.frame(thick = c(10.0, 10.0, 20.0, 12.5, 22.5, 30.0, 50.0, 40.0, 60.0, 95.0, 120.0),
                     code = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "1.", "4.")) # from table below
  if(nrow(x) == 0){
    vtab <- 0    
  } else {
    area <- x$AREA
    etab <- eggAttr(x$EGG_ATTR)
    etab$E_CA[is.na(etab$E_CA)] <- etab$E_CT[is.na(etab$E_CA)] # place total concentration in column a if only one ice type
    ct <- as.numeric(gsub("\\+", ".5", etab$E_CT))/10
    ca <- as.numeric(gsub("\\+", ".5", etab$E_CA))/10 # convert coverage to percent
    cb <- as.numeric(gsub("\\+", ".5", etab$E_CB))/10 
    cc <- as.numeric(gsub("\\+", ".5", etab$E_CC))/10 
    cd <- as.numeric(gsub("\\+", ".5", etab$E_CD))/10
    i <- which(is.na(etab$E_CD) & !is.na(etab$E_SD))
    if(length(i) > 0) cd[i] <- ct[i] - (ca[i] + cb[i] + cc[i]) # rule from ice manual
    ta <- stab$thick[match(etab$E_SA, stab$code)] * 1e-5 # thickness converted to km
    tb <- stab$thick[match(etab$E_SB, stab$code)] * 1e-5 # thickness converted to km
    tc <- stab$thick[match(etab$E_SC, stab$code)] * 1e-5 # thickness converted to km
    td <- stab$thick[match(etab$E_SD, stab$code)] * 1e-5 # thickness converted to km
    vtab <- data.frame(a=ca*ta*area, b=cb*tb*area, c=cc*tc*area, d=cd*td*area) # volume table
    vtab[is.na(vtab)] <- 0
    sum(rowSums(vtab))
  }
}

#######################################################################  
##' plotIce()-----------------------------
##' function for plotting ice charts
#'
#' @param x 
#' @param main 
#'
#' @return
#' @export
#'
#' @examples
plotIce <- function(x, main = "") {
  Blues <- colorRampPalette(brewer.pal(8, "Blues"))
  x <- spTransform(x, CRS("+proj=longlat +datum=WGS84"))
  ct <- as.numeric(gsub("\\+", ".5", eggAttr(x$EGG_ATTR)$E_CT))/10
  ct[is.na(ct)] <- 0
  cols <- rgb(1, 1, 1, ct)
  par(mar = c(3, 3, 3, 3), xaxs = "i", yaxs = "i")
  plot(x, axes = TRUE, col = "#084594", border = "#084594", main = main)
  plot(x, col = cols, border = NA, add = TRUE)
  plot(x[x$A_LEGEND == "Land", ], col = "grey60", border = "grey40", lwd = 0.5, add = TRUE)
}


##' e00_to_SpatialPolygonDataframe() ----------------------------------
##' e00 to avc_data (coverages) and then to SpatialPolygonsDAtaframe in sp_data
#'
#' @param x 
#'
#' @return
#' @export
#'
#' @examples

e00_to_SpatialPolygonDataframe <- function(x){
  for(i in x) {
    
    ## names
    e00file <- paste0("e00_data/", i, ".e00")
    spfile <- paste0("sp_data/", i, ".Rdata")
    avcdir <- paste0("avc_data/", i)
    if(!dir.exists(avcdir)) dir.create(avcdir)
    
    ## raw data
    raw <- readLines(e00file) # reads E00 file
    attr.tab <- attrTab(raw) # used attrTab (and eggAttr) functions to make attr.tab
    
    ## get data from  e00 file
    con <- try(e00toavc(e00file, file.path(avcdir, "bin")))
    arc <- try(get.arcdata(avcdir, "bin"))
    pal <- try(get.paldata(avcdir, "bin"))
    pat <- try(get.tabledata(file.path(avcdir, "info"), "bin.PAT")) # get.tablenames(file.path(avcdir, "info"))
    
    if(all(c(class(arc), class(pal)) != "try-error")) {
      
      ## convert data to spatial polygons
      lcc.proj <- "+proj=lcc +lat_1=49 +lat_2=77 +lat_0=40 +lon_0=-100 +x_0=0 +y_0=0 +datum=NAD27 +ellps=clrk66 +units=m +no_defs"
      ice <- pal2SpatialPolygons(arc,
                                 pal,
                                 pal[[1]]$PolygonId[-1],
                                 dropPoly1=TRUE,
                                 proj4string=CRS(lcc.proj))
      
      if(class(pat) != "try-error") {
        ## add table data to make spatial polygons data frame
        dat <- lapply(names(pat), function(i) {
          if(is.character(pat[[i]])) {
            gsub(pattern = "^\\s+|\\s+$", replacement = "", pat[[i]])
          } else {
            pat[[i]]
          }
        })
        dat <- do.call(cbind.data.frame, dat)
        names(dat) <- gsub(" ", "", names(pat))
        dat <- dat[-1, ] # discard first row
        dat[dat == ""] <- NA
        dat$ID <- as.character(seq(nrow(dat)))
      } else {
        ids <- data.frame(ID = sapply(slot(ice, "polygons"), function(x) slot(x, "ID")))
        ids <- na.omit(ids)
        dat <- merge(ids, attr.tab, by = "ID", all.x = TRUE)
        dat <- dat[order(as.numeric(dat$ID)),]
        dat$A_LEGEND[is.na(dat$A_LEGEND)] <- "No data"
        row.names(dat) <- dat$ID
      }
      ice <- try(SpatialPolygonsDataFrame(ice, data = dat))
      try(plotIce(ice, main = i))
      
      ## use cleangeo package to clean-up geometry errors
      ice <- try(clgeo_Clean(ice))
      
      ## save Rdata
      if(class(ice) != "try-error") {
        save(ice, file = spfile)
      }
    }
  }
}




#######################################################
## loadMap()----------------
#' loads maps from Rdata file
#'
#' @param y is a Rdata file
#'
#' @return ice - a Large Spatial Polygon
#' @export
#'
#' @examples ice <- loadMap(y)
loadMap <- function(y){
  #print(y[i])                   #start here when making single object for testing
  load(format(y[i], "sp_data/%Y%m%d.Rdata"))
  return(ice)
}


## subsetProject()------------
#' subset and project to WGS84 (poorly named)
#'
#' @param ice - a Large Spatial Polygon
#'
#' @return egg - a SpatialPolygonDataframe in WGS84
#' @export
#'
#' @examples egg <- subsetProject(ice)
subsetProject <- function(ice){
  #browser()
  egg <- ice[!is.na(ice$EGG_ATTR), ]  # subset
  egg <- spTransform(egg, CRS("+proj=longlat +datum=WGS84")) # convert to WGS84 bc filters are in WGS84 - used on line 460
  return(egg)
}


## filterEgg()------
#' Apply filters and return to lcc projection
#'
#' @param egg - a SpatialPolygonDataframe in WGS84
#'
#' @return sub.egg - a SpatialPolygonDataframe in lcc projection
#' @export
#'
#' @examples sub.egg <- filterEgg(egg)      
filterEgg <- function(egg) {
  #browser()
  attr.tab <- egg@data
  sub.egg <- try(gDifference(egg, filters, byid = TRUE))
  if(class(sub.egg) == "try-error") {
    print("try-error")
    buf.egg <- try(gBuffer(egg, byid = TRUE, width = 0)) # adding a small buffer often fixes geo issues
    sub.egg <- try(gDifference(buf.egg, filters, byid = TRUE)) # remove the egg areas with filters
  }
  if(class(sub.egg) != "try-error" & !is.null(sub.egg)) {
    row.names(attr.tab) <- paste(row.names(attr.tab), "- filters")
    attr.tab <- attr.tab[names(sub.egg), ]
    sub.egg <- SpatialPolygonsDataFrame(sub.egg, attr.tab) # recover data bc of gBuffer and gDifference which make a SP rather than an SPDF
  }
  if(class(sub.egg) == "try-error") { stop("There was a problem applying the filters") }
  return(sub.egg=sub.egg)
}

############################################################
## proceed with area and volume calculations
############################################################
##' calcPolyA()-----------
#' calculates the area of each polygon in SpatailPolygonDataframe
#' @param z list with subegg, minlat, and minlong
#'
#' @return
#' @export z list with subegg, minlat, and minlong and a (used to calculate area)
#'
#' @examples temp.ls <- calcPolyA(temp.ls)
#' temp.ls[[2]]$sub.egg1@data

calcPolyA <- function(z){
  #browser()
  a <- try(gArea(z, byid = TRUE)) # sometimes holes are not identified correctly, so try and extract max polygon area within each id
  if(class(a) == "try-error") { 
    message("gArea didn't work. Trying alternate approach")
    a <- sapply(slot(z, "polygons"), function(x) max(sapply(slot(x, "Polygons"), slot, "area"))) 
  }
  #z$sub.egg1$AREA <- a * 1e-6 # replace polygon area (use square km)
  #temp.ls$a <- a
  
  return(a=a)
}

##' trendsCalc()-------
#' use iceArea() and iceVolume() to calculate the area and volume of ice for specified area
#' @param x  list with subegg, minlat, and minlong and a (used to calculate area)
#'
#' @return list with area, volume, minlat, and minlong for a given date (from Rdata[i])
#' @export
#'
#' @examples calc <- trendsCalc(temp.ls)
trendsCalc <- function(x, y){
  #browser()
  if(class(y) != "try-error") {
    x@data$AREA <- y * 1e-6 # replace polygon area (use square km)
    subarea <- iceArea(x@data)
    area <- subarea[[2]]
    volume <- iceVolume(x@data) 
    #minlat <- iceTiming(sub.egg)
    
  }
  return(list(area=area, volume=volume, minlat=x$minlat, minlong=x$minlong))
  
} 


## calcLatLong()------
#' subset the sub.egg data by ice concentration and stage of development and calculate the minimum latitude (timing of iceretreat) using sub functions - needed to proceed with area and volume calculations
#'
#' @param sub.egg a SpatialPolygonDataframe in lcc projection
#' @param ct - total ice concentration
#' @param sa  - stage of ice development for thickest type of ice
#'
#' @return list with subegg, minlat, and minlong
#' @export
#'
#' @examples temp.ls <- calcLatLong(sub.egg, ct = m1$ct, sa = m1$sa)
#' test <- calcLatLong(sub.egg, ct = m2$ct, sa = m2$sa)

calcLatLong <- function(sub.egg, ct = NULL, sa = NULL) {
  #browser()
  
  sub.egg1 <- iceSubset(sub.egg, ct = ct, sa = sa) 
  
  if(nrow(sub.egg1@data)==0){ # if you subset out all data
    print("subset zero - rows")
    area <- volume <- 0
    minlat <- 55
    minlong <- -56
    sub.trend <- sp::spTransform(sub.egg, CRS(proj4string(ice)))
    
  } else {
    
    coords_min <- iceTiming(sub.egg1)
    minlat <- coords_min$lat
    minlong <- coords_min$long
    
    ## return to lcc projection and calculate area and volume bc e00 data is in lcc and meters - needed to get proper area/volume calculations
    ice <- get("ice", parent.frame())
    #ice@bbox <- sub.egg1@bbox
    sub.egg1 <- sp::spTransform(sub.egg1, CRS(proj4string(ice)))
    sub.poly <- calcPolyA(sub.egg1)
    sub.trend <- trendsCalc(sub.egg1, sub.poly)
    
    area <- sub.trend$area
    volume <- sub.trend$volume
    minlat <- minlat
    minlong <- minlong
  }
  
  return(list(area=area, volume=volume, minlat=minlat, minlong=minlong))
}

############################################################
# This is the end function - all of the above contribute to this one
############################################################
##' calcAreaVolLat()---------
#' Main function that brings together all the other functions 
#' @param y set of dates
#' @param ct concentration of sea ice
#' @param sa stage of ice development
#'
#' @return a list of areas, volumes, minlats, and minlongs for a series of dates
#' @export
#'
#' @examples test <- calcAreaVolLat(dates3, ct=m1$ct, sa=m1$sa)
#' test <- calcAreaVolLat(dates3[1], ct=m2$ct, sa=m2$sa)
#' test <- calcAreaVolLat(dates3[2], ct=m2$ct, sa=m2$sa)
calcAreaVolLat <- function(y, ct = NULL, sa = NULL) {
  #browser()
  #my.env <- new.env()
  areas <-
    volumes <-
    minlats <- minlongs <- rep(NA, length(y)) # create an empty object
  for (i in seq_along(y)) {
    ## load map data
    print(y[i])                   #start here when making single object for testing
    load(format(y[i], "sp_data/%Y%m%d.Rdata"))
    ## set area and volume to 0 if no egg attributes
    #print("inside cAVL")
    #print(where("ice"))
    #crs <- CRS("+proj=lcc +lat_1=49 +lat_2=77 +lat_0=40 +lon_0=-100 +x_0=0 +y_0=0 +datum=NAD27")
    #ice <- ice
    if (all(is.na(ice$EGG_ATTR))) {
      print("is NA")
      area <- volume <- 0
      minlat <- 55
      minlong <- -58
    } else {
      egg <- subsetProject(ice)    # ice is not in the local environment
      sub.egg <- filterEgg(egg)
      
      if (is.null(sub.egg)) {
        print("is null")
        area <- volume <- 0
        minlat <- 55 # if NULL, then no ice was below 55 deg North
        minlong <- -57
      } else {
        if (class(sub.egg) != "try-error") {
          calc <- calcLatLong(sub.egg, ct = ct, sa = sa)
          
          
          area <- calc$area
          volume <- calc$volume
          minlat <- calc$minlat
          minlong <- calc$minlong
        } else {
          area <- volume <- minlat <- minlong <-  NA
        }
      }
    }
    
    areas[i] <- area 
    volumes[i] <- volume
    minlats[i] <- minlat
    minlongs[i] <- minlong
  }
  list(
    areas = areas,
    volumes = volumes,
    minlats = minlats,
    minlongs = minlongs
  )
}


############################################################
## Below here are other functions for other work
####################################################################################
##' multiplot()--------- 
#' - like mfrow
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)
  
  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)
  
  numPlots = length(plots)
  
  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                     ncol = cols, nrow = ceiling(numPlots/cols))
  }
  
  if (numPlots==1) {
    print(plots[[1]])
    
  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
    
    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
      
      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}


####################################################################################
## PrintLvls() -----------------------------------------------------
# prints levels of an object
# copied from http://r.789695.n4.nabble.com/List-of-Levels-for-all-Factor-variables-td4646355.html
# use this in the Look at Data function to print out levels of all factor variables
PrintLvls <- function(x) {print(data.frame(Lvls=sapply(x[sapply(x,is.factor)],nlevels), 
                                           Names=sapply(x[sapply(x, is.factor)], 
                                                        function(y) paste0(levels(y), collapse=", "))), right=FALSE) 
} 

##' lookAT()--------------------
#' function for printing the head and str of a data set
#' @param x 
#'
#' @return
#' @export
#'
#' @examples - lookAt(iris) # prints head of data set and structure

lookAt <- function(x) {
  print(head(x))
  cat("\n")
  str(x)
  cat("\n")
  cat("Names of levels in Factor Variables")
  cat("\n")
  PrintLvls(x) #see above for code
}

## lookAtSubEgg() -------------
#' Look At the STructure of a sub.egg object
#'
#' @param z = a vector of dates
#' @param i = a datum in the vector
#'
#' @return an ice object which is in an LCC projection; ice is the unfiltered e00 file in RData form, sub.egg is filtered ice
#' @export
#'
#' @examples
lookAtIce <- function(z, i, ct = NULL, sa = NULL){
  #browser()
  print(z[i])                   #start here when making single object for testing
  load(format(z[i], "sp_data/%Y%m%d.Rdata"))
  #plotIce(ice, main = dates[i])
  iceLook <- ice
  showIce <- ice@data[, c("AREA", "A_LEGEND", "EGG_ATTR", "E_CT", "E_CA", "E_SA", "E_SB")]
  egg <- subsetProject(ice)    # ice is not in the local environment
  sub.egg <- filterEgg(egg)
  sub.egg1 <- iceSubset(sub.egg, ct = ct, sa = sa) 
  
  return(list(a=iceLook, b=showIce, c=sub.egg1))
}


extractSubegg1 <- function(z, i, ct = NULL, sa = NULL){
  #browser()
  print(z[i])                   #start here when making single object for testing
  load(format(z[i], "sp_data/%Y%m%d.Rdata"))
  #plotIce(ice, main = dates[i])
  egg <- subsetProject(ice)    # ice is not in the local environment
  sub.egg <- filterEgg(egg)
  sub.egg1 <- iceSubset(sub.egg, ct = ct, sa = sa) 
  
  sub.egg1 <- sp::spTransform(sub.egg1, CRS(proj4string(ice)))
  out <- iceArea(sub.egg1)
  #sub.poly <- calcPolyA(sub.egg1)
  #sub.trend <- trendsCalc(sub.egg1, sub.poly)
  return(out)
}

##################################################################################################### OPtimization funcitons
##  SSQCapelinDome()--------------
### Feb 3 2015 - ADB
### Code to fit the ice capelin model presented in Buren et al 2014
### this is not elegant code, but at the time I ran the nalyses was good enough
### I define 2 functions: one is the objective function SSQCapelinDome   and the second function
### obtains the Expected Log Capelin BIomass (CapelinDome)

### The data must be stored in a dataframe called capelin with at least 3 columns: 'year','tice','logcapelin'
### logcapelin is the observed capelin biomass (in log scale). The data frame capelin cancontain more columns
### NA values of logcapelin (i.e. years when there were no capelin surveys) are not used during optimization

## Objective function - part of optimization function
SSQCapelinDome <- function(params,dataf){
  Alpha <- params[1]
  Beta <- params[2]
  Gamma <- params[3]
  year <- dataf[,1]
  tice <- dataf[,2]
  logcap <- dataf[,3]
  ELogCapBiom <- ifelse(year<1991, Alpha*tice*(1-(tice/Beta)), Alpha*tice*(1-(tice/Beta))*Gamma)
  sum((logcap-ELogCapBiom)^2)
}

## Function to obtain Expected Log Capelin Biomass         
CapelinDome <- function(params,dataf){
  Alpha <- params[1]
  Beta <- params[2]
  Gamma <- params[3]
  year <- dataf[,1]
  tice <- dataf[,2]
  ELogCapBiom <- ifelse(year<1991, Alpha*tice*(1-(tice/Beta)), Alpha*tice*(1-(tice/Beta))*Gamma)
  ELogCapBiom
}


#####################################################################################################
##' modelGraphs()-------------
#' figure for plotting predicted values of models over a range of years
#' @param x = years
#'
#' @return graphs from 1970-2016 (or based on vector)
#' @export
#'
#' @examples modelGraphs(years)
modelGraphs <- function(years){
  for(i in seq_along(years)) {
    
    ## subset data
    mod.dat <- trends[year == years[i]]
    mod.dat$t <- mod.dat$doy
    mod.dat$a <- mod.dat$area/1000
    mod.p <- ggplot(mod.dat) + 
      geom_point(aes(x = t, y = a)) + 
      theme_bw() + 
      xlab('Day of Year (NOV - JUL)') +
      ylab('Area') +
      theme(panel.grid.major = element_line(linetype = "dotted")) # make base layer and plot data
    
    
    ## extract basic parameters
    raw.amax[i] <- max(mod.dat$a)
    raw.tmax[i] <- mod.dat$t[which.max(mod.dat$a)]
    
    ## approx start vals
    j <- which(mod.dat$a > quantile(mod.dat$a, prob = 0.50)) # top values
    h <- max(mod.dat$a[j]) / sqrt(2 * pi)
    s <- max(mod.dat$t[j]) - min(mod.dat$t[j])
    tm <- mean(mod.dat$t[j])
    # b <- h/tm
    
    ## run models
    mod1 <- try(nls(a ~ (h / sqrt(2 * pi)) * (exp(-((t - tm) ^ 2) / (2 * s ^ 2))), 
                    data = mod.dat, 
                    start = list(h = h, s = s, tm = tm),
                    lower = c(0, 0, -60), # except for tm (let search back to Nov 1 [doy -60]), constrain to positive parameter space 
                    control = nls.control(maxiter = 100), 
                    algorithm = "port"))
    mod2 <- try(nls(a ~ (h / sqrt(2 * pi)) * (exp(-((t - tm) ^ 2) / (2 * ifelse(t < tm, s1, s2) ^ 2))),  # see http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2993707/   
                    data = mod.dat, 
                    start = list(h = h, s1 = s/2, s2 = s/2, tm = tm),
                    lower = c(0, 0, 0, -60), # except for tm (let search back to Nov 1 [doy -60]), constrain to positive parameter space
                    control = nls.control(maxiter = 100),
                    algorithm = "port"))
    
    if(class(mod1) != "try-error" | class(mod2) != "try-error") {
      
      ## predict
      preds <- data.frame(t = min(mod.dat$t):max(mod.dat$t))
      if(class(mod1) != "try-error") preds$mod1 <- predict(mod1, newdata = preds)
      if(class(mod2) != "try-error") preds$mod2 <- predict(mod2, newdata = preds)
      preds <- data.table(preds)
      preds <- melt(preds, id.var = "t", variable.name = "mod", value.name = "a")
      
      if(class(mod2) != "try-error") {
        amax[i] <- coefficients(mod2)["h"] / sqrt(2 * pi)
        tmax[i] <- coefficients(mod2)["tm"]
        tstart[i] <- coefficients(mod2)["tm"] - sqrt(-2 * log(0.20)) * coefficients(mod2)["s1"] # start of advance (20% of amax)
        tend[i] <- coefficients(mod2)["tm"] + sqrt(-2 * log(0.20)) * coefficients(mod2)["s2"] # end of retreat (20% of amax)
        adv.mag[i] <- coefficients(mod2)["h"] * coefficients(mod2)["s1"] / 2
        ret.mag[i] <- coefficients(mod2)["h"] * coefficients(mod2)["s2"] / 2
        #round(mod.amax[i] * 0.20, 3) == round(predict(mod2, newdata = data.frame(t = ret.end[i])), 3) # check math
        ## calculate advance and retreat maginitude
        
        x <- c(tmax[i], tstart[i], tend[i])
        y <- predict(mod2, newdata = data.frame(t = x))
        seg.df <- data.frame(x1 = x, x2 = x, y1 = rep(0, length(y)), y2 = y)
        mod.p <- mod.p + 
          #geom_ribbon(aes(x = t, ymin = 0, ymax = a), 
          #                           data = preds[mod == "mod2"],
          #                           fill = "#00BFC4", alpha = 0.15) +
          geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2), 
                       data = seg.df, linetype = "dashed", col = "#00BFC4") +
          geom_hline(yintercept = amax[i], linetype = "dashed", col = "#00BFC4") # plots intersection - not sure of what yet
      }
      
      ## add prediction to plot 
      mod.p <- mod.p + 
        geom_line(aes(x = t, y = a, col = mod), preds, size = 0.7) # plots the predicted values 
      #labs(mod = "Model") #- tried to change the legend
      
      #scale_fill_continuous(guide = guide_legend(title = "Model"))  
    }
    
    ## print plot and clean-up
    print(mod.p + ggtitle(years[i])) # add the years
    rm(mod1, mod2)
    
  }
  
  
}
